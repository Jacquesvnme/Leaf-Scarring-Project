{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spots detected: 7\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def count_spots(image_path):\n",
    "    # Step 1: Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Step 2: Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Step 3: Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "    \n",
    "    # Step 4: Apply a binary threshold to the image\n",
    "    _, thresh = cv2.threshold(blurred, 120, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Step 5: Find contours (which represent the spots)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Count the number of spots (contours)\n",
    "    number_of_spots = len(contours)\n",
    "    \n",
    "    # Draw contours on the original image\n",
    "    output_image = image.copy()\n",
    "    cv2.drawContours(output_image, contours, -1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the original image with spots highlighted\n",
    "    cv2.imshow(\"Detected Spots\", output_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return number_of_spots\n",
    "\n",
    "# Example usage\n",
    "image_path = '360_F_457474202_N4CKJyXw5AIIzOF7YNW9d71GoGmXDfqo.jpg'  # Replace with the path to your leaf image\n",
    "spots_count = count_spots(image_path)\n",
    "print(f\"Number of spots detected: {spots_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SearchBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scars detected: 1515\n",
      "Output image saved at: scars_detected_output.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def is_scar_color(pixel, scar_color_lower, scar_color_upper):\n",
    "    \"\"\"Check if the given pixel color is within the scar color range.\"\"\"\n",
    "    return np.all(pixel >= scar_color_lower) and np.all(pixel <= scar_color_upper)\n",
    "\n",
    "def count_scar_spots(image_path, window_size=2, step_size=2, scar_color_lower=(76, 68, 58), scar_color_upper=(244, 243, 245)):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    # Create a copy of the image for visualization\n",
    "    output_image = image.copy()\n",
    "\n",
    "    # Initialize a counter for the number of scars\n",
    "    scar_count = 0\n",
    "\n",
    "    # Loop over the image using a sliding window\n",
    "    for y in range(0, height - window_size, step_size):\n",
    "        for x in range(0, width - window_size, step_size):\n",
    "            # Extract the region of interest (window)\n",
    "            window = image[y:y + window_size, x:x + window_size]\n",
    "            \n",
    "            # Check if the window contains scar-like colors\n",
    "            found_scar = False\n",
    "            for row in window:\n",
    "                for pixel in row:\n",
    "                    if is_scar_color(pixel, scar_color_lower, scar_color_upper):\n",
    "                        found_scar = True\n",
    "                        break  # Stop scanning this window if a match is found\n",
    "            \n",
    "            if found_scar:\n",
    "                # Increment the scar counter\n",
    "                scar_count += 1\n",
    "\n",
    "                # Draw a rectangle around the detected scar region\n",
    "                cv2.rectangle(output_image, (x, y), (x + window_size, y + window_size), (0, 255, 0), 2)\n",
    "\n",
    "    # Save the output image with marked scars\n",
    "    output_path = 'scars_detected_output.png'\n",
    "    cv2.imwrite(output_path, output_image)\n",
    "    \n",
    "    # Optionally, display the output image\n",
    "    cv2.imshow('Scars Detected', output_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return scar_count, output_path\n",
    "\n",
    "# Example usage\n",
    "image_path = 'OneLeaf.PNG'  # Replace with the path to your image\n",
    "scar_color_lower = (76, 68, 58)  # Lower BGR bound for scar detection (darker values)\n",
    "scar_color_upper = (244, 243, 245)  # Upper BGR bound for scar detection (lighter values)\n",
    "\n",
    "scar_count, output_image_path = count_scar_spots(image_path, window_size=20, step_size=10, scar_color_lower=scar_color_lower, scar_color_upper=scar_color_upper)\n",
    "\n",
    "print(f\"Number of scars detected: {scar_count}\")\n",
    "print(f\"Output image saved at: {output_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scars detected: 1477\n",
      "Output image saved at: scars_and_leaf_output.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def is_scar_color(pixel, scar_color_lower, scar_color_upper):\n",
    "    \"\"\"Check if the given pixel color is within the scar color range.\"\"\"\n",
    "    return np.all(pixel >= scar_color_lower) and np.all(pixel <= scar_color_upper)\n",
    "\n",
    "def count_scar_spots(image_path, window_size=20, step_size=10, scar_color_lower=(76, 68, 58), scar_color_upper=(244, 243, 245)):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    # Convert the image to grayscale and apply thresholding to segment the leaf\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours (the boundary of the leaf)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the largest contour which will likely be the leaf's boundary\n",
    "    leaf_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Create a mask to isolate the leaf region\n",
    "    mask = np.zeros_like(gray)\n",
    "    cv2.drawContours(mask, [leaf_contour], -1, 255, thickness=cv2.FILLED)\n",
    "    \n",
    "    # Create an output image for visualization\n",
    "    output_image = image.copy()\n",
    "\n",
    "    # Initialize a counter for the number of scars\n",
    "    scar_count = 0\n",
    "\n",
    "    # Loop over the image using a sliding window, but only process pixels inside the leaf contour\n",
    "    for y in range(0, height - window_size, step_size):\n",
    "        for x in range(0, width - window_size, step_size):\n",
    "            # Only process the window if it's inside the leaf boundary\n",
    "            if np.any(mask[y:y + window_size, x:x + window_size] == 255):  # Check if the window is inside the leaf\n",
    "                window = image[y:y + window_size, x:x + window_size]\n",
    "                \n",
    "                found_scar = False\n",
    "                for row in window:\n",
    "                    for pixel in row:\n",
    "                        if is_scar_color(pixel, scar_color_lower, scar_color_upper):\n",
    "                            found_scar = True\n",
    "                            break  # Stop scanning this window if a match is found\n",
    "                \n",
    "                if found_scar:\n",
    "                    # Increment the scar counter\n",
    "                    scar_count += 1\n",
    "\n",
    "                    # Draw a rectangle around the detected scar region\n",
    "                    cv2.rectangle(output_image, (x, y), (x + window_size, y + window_size), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw the leaf contour on the output image\n",
    "    cv2.drawContours(output_image, [leaf_contour], -1, (0, 0, 255), 3)\n",
    "\n",
    "    # Save the output image with marked scars and leaf outline\n",
    "    output_path = 'scars_and_leaf_output.png'\n",
    "    cv2.imwrite(output_path, output_image)\n",
    "\n",
    "    # Optionally, display the output image\n",
    "    cv2.imshow('Leaf with Scars Detected', output_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return scar_count, output_path\n",
    "\n",
    "# Example usage\n",
    "image_path = 'OneLeaf.PNG'  # Replace with the path to your image\n",
    "scar_color_lower = (76, 68, 58)  # Lower BGR bound for scar detection\n",
    "scar_color_upper = (244, 243, 245)  # Upper BGR bound for scar detection\n",
    "\n",
    "scar_count, output_image_path = count_scar_spots(image_path, window_size=20, step_size=10, scar_color_lower=scar_color_lower, scar_color_upper=scar_color_upper)\n",
    "\n",
    "print(f\"Number of scars detected: {scar_count}\")\n",
    "print(f\"Output image saved at: {output_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('OneLeaf.PNG')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Enhance contrast using CLAHE\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "contrast_image = clahe.apply(gray_image)\n",
    "\n",
    "# Thresholding to separate lighter colors from darker colors\n",
    "# You can adjust the threshold value (e.g., 127) as needed\n",
    "_, thresholded_image = cv2.threshold(contrast_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Show the results\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Grayscale Image', gray_image)\n",
    "cv2.imshow('Contrast Enhanced Image', contrast_image)\n",
    "cv2.imshow('Thresholded Image', thresholded_image)\n",
    "\n",
    "# Wait until a key is pressed and close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('Leaf_1.png')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian Blur to smooth the image and reduce details like veins\n",
    "blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "# Alternatively, you can use Median Blur\n",
    "# blurred_image = cv2.medianBlur(gray_image, 5)\n",
    "\n",
    "# Enhance contrast using CLAHE\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "contrast_image = clahe.apply(blurred_image)\n",
    "\n",
    "# Thresholding to separate lighter colors from darker colors\n",
    "# Adjust the threshold value (e.g., 127) as needed\n",
    "_, thresholded_image = cv2.threshold(contrast_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Show the results\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Grayscale Image', gray_image)\n",
    "cv2.imshow('Blurred Image', blurred_image)\n",
    "cv2.imshow('Contrast Enhanced Image', contrast_image)\n",
    "cv2.imshow('Thresholded Image', thresholded_image)\n",
    "\n",
    "# Wait until a key is pressed and close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('Leaf_1.PNG')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian Blur to smooth the image\n",
    "blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "# Thresholding to create a mask for the scars\n",
    "_, mask = cv2.threshold(blurred_image, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Use morphological operations to refine the mask if needed\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)  # Close small holes in the mask\n",
    "\n",
    "# Inpaint the image using the mask\n",
    "inpainted_image = cv2.inpaint(image, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
    "\n",
    "# Specify the directory to save the images\n",
    "save_directory = r'Leaf-Scarring-Project-main\\Individual_Code\\Henko Holl'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Save the images\n",
    "cv2.imwrite(os.path.join(save_directory, 'Original_Image.png'), image)\n",
    "cv2.imwrite(os.path.join(save_directory, 'Mask_for_Scars.png'), mask)\n",
    "cv2.imwrite(os.path.join(save_directory, 'Inpainted_Image.png'), inpainted_image)\n",
    "\n",
    "# Show the results\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Mask for Scars', mask)\n",
    "cv2.imshow('Inpainted Image', inpainted_image)\n",
    "\n",
    "# Wait until a key is pressed and close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the mask image (output from the previous program)\n",
    "mask_image_path = r'Leaf_1.png'\n",
    "mask = cv2.imread(mask_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Find contours of the scars in the mask\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create an empty image to draw contours\n",
    "contour_image = np.zeros_like(mask)\n",
    "\n",
    "# Draw contours and count them\n",
    "scar_count = 0\n",
    "for contour in contours:\n",
    "    if cv2.contourArea(contour) > 100:  # Filter out small contours if needed\n",
    "        scar_count += 1\n",
    "        cv2.drawContours(contour_image, [contour], -1, (255), 2)  # Draw contours in white\n",
    "\n",
    "# Specify the directory to save the images\n",
    "save_directory = r'Leaf-Scarring-Project-main\\Individual_Code\\Henko Holl'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Save the mask and the image with contours\n",
    "cv2.imwrite(os.path.join(save_directory, 'Mask_for_Scars.png'), mask)\n",
    "cv2.imwrite(os.path.join(save_directory, 'Contours_on_Mask.png'), contour_image)\n",
    "\n",
    "# Display the scar count on the contour image\n",
    "cv2.putText(contour_image, f'Scar Count: {scar_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255), 2)\n",
    "\n",
    "# Show the results\n",
    "cv2.imshow('Mask for Scars', mask)\n",
    "cv2.imshow('Contours on Mask', contour_image)\n",
    "\n",
    "# Wait until a key is pressed and close the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('Leaf_1.png')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian blur with a smaller kernel\n",
    "blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "# Apply adaptive thresholding\n",
    "mask = cv2.adaptiveThreshold(blurred, 255, \n",
    "                             cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                             cv2.THRESH_BINARY_INV, \n",
    "                             11, 2)\n",
    "\n",
    "# Optionally, apply morphological operations to clean up the mask\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "# Display the original and masked images\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Masked Image', masked_image)\n",
    "\n",
    "# Save the masked image\n",
    "cv2.imwrite('masked_leaf_image.jpg', masked_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "48628.5\n",
      "77.5\n",
      "29.0\n",
      "43.0\n",
      "99.0\n",
      "43.0\n",
      "19.0\n",
      "30.0\n",
      "19.0\n",
      "182.5\n",
      "24.0\n",
      "64.0\n",
      "50.0\n",
      "221.0\n",
      "698.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "64.5\n",
      "44.0\n",
      "73.0\n",
      "197.5\n",
      "126.0\n",
      "197.5\n",
      "0.0\n",
      "34.5\n",
      "152.0\n",
      "195.0\n",
      "37.0\n",
      "637.0\n",
      "19.0\n",
      "26.0\n",
      "32.0\n",
      "103.5\n",
      "117.5\n",
      "523.5\n",
      "19.0\n",
      "51.5\n",
      "37.0\n",
      "length =  0.0\n",
      "area =  0.0\n",
      "[91 11] \n",
      "\n",
      "Contour points: 1 \n",
      "\n",
      "arcLength: 0.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"OneLeaf.png\", cv2.IMREAD_GRAYSCALE)\n",
    "scale_percent = 60 # percent of original size\n",
    "width = int(img.shape[1] * scale_percent / 100)\n",
    "height = int(img.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "  \n",
    "# resize image\n",
    "resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# threshold to binary\n",
    "thresh = cv2.threshold(resized, 210, 255, cv2.THRESH_BINARY_INV)[1]  # the 2nd parameter should be changed.\n",
    "\n",
    "# apply morphology\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (4,4))\n",
    "morph = cv2.morphologyEx(thresh, cv2.MORPH_ERODE, kernel, 1)\n",
    "\n",
    "letter = morph.copy()\n",
    "cntrs = cv2.findContours(morph, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  \n",
    "# cntrs = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  \n",
    "\n",
    "cntrs = cntrs[0] if len(cntrs) == 2 else cntrs[1]\n",
    "# cntrs = cntrs[0]\n",
    "\n",
    "for c in cntrs:\n",
    "    area = cv2.contourArea(c)\n",
    "    print(area)\n",
    "    if area < 100:\n",
    "        cv2.drawContours(letter,[c],0,(0,0,0),-1)\n",
    "\n",
    "\n",
    "# do canny edge detection\n",
    "edges = cv2.Canny(letter, 200, 200) # the result for edges is good.\n",
    "length = cv2.arcLength(cntrs[0], False)  # not closed curves\n",
    "print('length = ',length)  # both length and area need calibration\n",
    "\n",
    "area = cv2.contourArea(cntrs[0])\n",
    "print('area = ',area)\n",
    "\n",
    "# Outputs\n",
    "print(np.squeeze(cntrs[0]), '\\n')                    # Contour\n",
    "print('Contour points:', cntrs[0].shape[0], '\\n')\n",
    "print('arcLength:', cv2.arcLength(cntrs[0], True))  # closed curves\n",
    "\n",
    "# write results\n",
    "# cv2.imwrite(\"K_thresh.png\", thresh)    \n",
    "\n",
    "# show results\n",
    "# cv2.imshow(\"K_thresh\", thresh)\n",
    "# cv2.imshow(\"K_morph\", morph)\n",
    "cv2.imshow(\"K_letter\", letter)\n",
    "cv2.imshow(\"K_edges\", edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
